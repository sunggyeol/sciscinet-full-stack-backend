{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef3b9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SciSciNet Validation Notebook ===\n",
      "Python version: 3.12.9 (main, Feb 12 2025, 14:39:53) [GCC 6.3.0 20170516]\n",
      "Pandas version: 2.3.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=== SciSciNet Validation Notebook ===\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\\n\")\n",
    "\n",
    "DATA_DIR = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56566126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset File Validation ===\n",
      "\n",
      "Data directory: ../data\n",
      "\n",
      "[OK] SciSciNet_Affiliations.tsv                        3.26 MB\n",
      "[OK] SciSciNet_Fields.tsv                              0.01 MB\n",
      "[OK] SciSciNet_Papers.tsv                             16.46 GB\n",
      "[OK] SciSciNet_PaperDetails.tsv                       28.72 GB\n",
      "[OK] SciSciNet_PaperAuthorAffiliations.tsv            11.68 GB\n",
      "[OK] SciSciNet_PaperFields.tsv                        11.62 GB\n",
      "[OK] SciSciNet_PaperReferences.tsv                    32.41 GB\n",
      "\n",
      "All 7 required files found\n"
     ]
    }
   ],
   "source": [
    "required_files = [\n",
    "    'SciSciNet_Affiliations.tsv',\n",
    "    'SciSciNet_Fields.tsv',\n",
    "    'SciSciNet_Papers.tsv',\n",
    "    'SciSciNet_PaperDetails.tsv',\n",
    "    'SciSciNet_PaperAuthorAffiliations.tsv',\n",
    "    'SciSciNet_PaperFields.tsv',\n",
    "    'SciSciNet_PaperReferences.tsv'\n",
    "]\n",
    "\n",
    "print(\"=== Dataset File Validation ===\\n\")\n",
    "print(f\"Data directory: {DATA_DIR}\\n\")\n",
    "\n",
    "missing_files = []\n",
    "existing_files = []\n",
    "\n",
    "for file in required_files:\n",
    "    file_path = os.path.join(DATA_DIR, file)\n",
    "    if os.path.exists(file_path):\n",
    "        size_mb = os.path.getsize(file_path) / (1024**2)\n",
    "        size_gb = size_mb / 1024\n",
    "        if size_gb >= 1:\n",
    "            print(f\"[OK] {file:45} {size_gb:>8.2f} GB\")\n",
    "        else:\n",
    "            print(f\"[OK] {file:45} {size_mb:>8.2f} MB\")\n",
    "        existing_files.append(file)\n",
    "    else:\n",
    "        print(f\"[MISSING] {file}\")\n",
    "        missing_files.append(file)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\nMissing {len(missing_files)} required files\")\n",
    "    validation_passed = False\n",
    "else:\n",
    "    print(f\"\\nAll {len(required_files)} required files found\")\n",
    "    validation_passed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "542a4777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading Affiliations Dataset ===\n",
      "\n",
      "Total affiliations: 26,998\n",
      "Columns: ['AffiliationID', 'Affiliation_Name', 'GridID', 'Official_Page', 'ISO3166Code', 'Latitude', 'Longitude', 'H-index', 'Productivity', 'Average_C10', 'Average_LogC10']\n",
      "\n",
      "First 5 rows:\n",
      "   AffiliationID                             Affiliation_Name         GridID  \\\n",
      "0       20455151                                  Air Liquide  grid.476009.c   \n",
      "1       24386293     Hellenic National Meteorological Service            NaN   \n",
      "2       32956416              Catholic University of the West  grid.448708.7   \n",
      "3       35926432                       Mackay Medical College  grid.452449.a   \n",
      "4       37448385  Chinese People's Public Security University            NaN   \n",
      "\n",
      "                                       Official_Page ISO3166Code   Latitude  \\\n",
      "0  https://web.archive.org/web/20100205175402/htt...          GB  52.503593   \n",
      "1         http://www.hnms.gr/hnms/english/index_html          GR  37.976140   \n",
      "2                                 http://www.uco.fr/          FR  47.464720   \n",
      "3                             http://www.mmc.edu.tw/          TW  25.254360   \n",
      "4                           http://www.ppsuc.edu.cn/          CN  39.904690   \n",
      "\n",
      "    Longitude  H-index  Productivity  Average_C10  Average_LogC10  \n",
      "0   -1.805160       65          1503    15.708827        1.793917  \n",
      "1   23.736400       19            87    69.310345        2.798667  \n",
      "2   -0.548610       37           344    22.126050        2.270640  \n",
      "3  121.495087       67          2286    21.061611        2.354786  \n",
      "4  116.407173       27          1875     0.792123        0.161562  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Loading Affiliations Dataset ===\\n\")\n",
    "\n",
    "affiliations_file = os.path.join(DATA_DIR, 'SciSciNet_Affiliations.tsv')\n",
    "df_affiliations = pd.read_csv(affiliations_file, sep='\\t')\n",
    "\n",
    "print(f\"Total affiliations: {len(df_affiliations):,}\")\n",
    "print(f\"Columns: {list(df_affiliations.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df_affiliations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac6b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Searching for Virginia Tech (Main Campus) ===\n",
      "\n",
      "FOUND: Virginia Tech main campus\n",
      "\n",
      "========================================================================================================================\n",
      " AffiliationID Affiliation_Name ISO3166Code      Official_Page\n",
      "     859038795    Virginia Tech          US http://www.vt.edu/\n",
      "========================================================================================================================\n",
      "\n",
      "Virginia Tech Affiliation ID: [859038795]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Searching for Virginia Tech (Main Campus) ===\\n\")\n",
    "\n",
    "name_column = 'Affiliation_Name'\n",
    "id_column = 'AffiliationID'\n",
    "\n",
    "# Search for main Virginia Tech campus only\n",
    "vt_main = df_affiliations[\n",
    "    (df_affiliations[id_column] == 859038795)\n",
    "]\n",
    "\n",
    "if len(vt_main) > 0:\n",
    "    print(f\"FOUND: Virginia Tech main campus\\n\")\n",
    "    print(\"=\"*120)\n",
    "    display_cols = [id_column, name_column, 'ISO3166Code', 'Official_Page']\n",
    "    available_cols = [col for col in display_cols if col in vt_main.columns]\n",
    "    print(vt_main[available_cols].to_string(index=False))\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    vt_affiliation_ids = [859038795]\n",
    "    print(f\"\\nVirginia Tech Affiliation ID: {vt_affiliation_ids}\")\n",
    "    \n",
    "    affiliation_id_col = id_column\n",
    "    affiliation_name_col = name_column\n",
    "    all_vt_results = vt_main\n",
    "    \n",
    "    validation_passed = validation_passed and True\n",
    "else:\n",
    "    print(\"\\nWARNING: Virginia Tech main campus not found\")\n",
    "    validation_passed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa1b619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading Fields Dataset ===\n",
      "\n",
      "Total fields: 311\n",
      "Columns: ['FieldID', 'Field_Name', 'Field_Type']\n",
      "\n",
      "First 10 rows:\n",
      "     FieldID                         Field_Name Field_Type\n",
      "0    3079626            Quantum electrodynamics        Sub\n",
      "1   37914503               Mathematical physics        Sub\n",
      "2  159047783                           Virology        Sub\n",
      "3   70410870                Clinical psychology        Sub\n",
      "4  187212893                         Pediatrics        Sub\n",
      "5   61434518                    General surgery        Sub\n",
      "6   73484699                        Criminology        Sub\n",
      "7  200601418            Reliability engineering        Sub\n",
      "8   95457728                            History        Top\n",
      "9  107826830  Environmental resource management        Sub\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Loading Fields Dataset ===\\n\")\n",
    "\n",
    "fields_file = os.path.join(DATA_DIR, 'SciSciNet_Fields.tsv')\n",
    "df_fields = pd.read_csv(fields_file, sep='\\t')\n",
    "\n",
    "print(f\"Total fields: {len(df_fields):,}\")\n",
    "print(f\"Columns: {list(df_fields.columns)}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(df_fields.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea56c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Defining All Computer Science Related Fields ===\n",
      "\n",
      "Defined 39 CS-related field IDs\n",
      "Using name column: 'Field_Name'\n",
      "Using ID column: 'FieldID'\n",
      "\n",
      "FOUND: 39 Computer Science related fields\n",
      "\n",
      "========================================================================================================================\n",
      "   FieldID                   Field_Name\n",
      " 113775141         Computer engineering\n",
      " 124101348                  Data mining\n",
      "  56739046         Knowledge management\n",
      " 149635348              Embedded system\n",
      " 107457646   Human–computer interaction\n",
      "  11413529                    Algorithm\n",
      "  28490314           Speech recognition\n",
      " 111919701             Operating system\n",
      "  31972630              Computer vision\n",
      "  77088390                     Database\n",
      " 108827166             Internet privacy\n",
      "  76155785           Telecommunications\n",
      "   9390403            Computer hardware\n",
      " 154945302      Artificial intelligence\n",
      "  49774154                   Multimedia\n",
      "    459310        Computational science\n",
      " 199360897         Programming language\n",
      "  38652104            Computer security\n",
      "  79403827          Real-time computing\n",
      "  41008148             Computer science\n",
      " 204321447  Natural language processing\n",
      " 188147891            Cognitive science\n",
      " 136764020               World Wide Web\n",
      " 147597530      Computational chemistry\n",
      " 120314980        Distributed computing\n",
      "  80444323 Theoretical computer science\n",
      "  60644358               Bioinformatics\n",
      " 115903868         Software engineering\n",
      "2522767166                 Data science\n",
      "  31258907             Computer network\n",
      " 119857082             Machine learning\n",
      "  44154836                   Simulation\n",
      " 173608175           Parallel computing\n",
      "  23123220        Information retrieval\n",
      "  30475298        Computational physics\n",
      " 121684516   Computer graphics (images)\n",
      " 178980831          Pattern recognition\n",
      " 118524514        Computer architecture\n",
      "  70721500        Computational biology\n",
      "========================================================================================================================\n",
      "\n",
      "Total CS Field IDs: 39\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Defining All Computer Science Related Fields ===\\n\")\n",
    "\n",
    "# Comprehensive list of CS-related field IDs\n",
    "cs_related_field_ids = [\n",
    "    # Core Computer Science\n",
    "    41008148,    # Computer science (Top)\n",
    "    113775141,   # Computer engineering\n",
    "    80444323,    # Theoretical computer science\n",
    "    459310,      # Computational science\n",
    "    \n",
    "    # AI & Machine Learning\n",
    "    154945302,   # Artificial intelligence\n",
    "    119857082,   # Machine learning\n",
    "    178980831,   # Pattern recognition\n",
    "    28490314,    # Speech recognition\n",
    "    31972630,    # Computer vision\n",
    "    204321447,   # Natural language processing\n",
    "    \n",
    "    # Data & Information\n",
    "    124101348,   # Data mining\n",
    "    2522767166,  # Data science\n",
    "    77088390,    # Database\n",
    "    23123220,    # Information retrieval\n",
    "    56739046,    # Knowledge management\n",
    "    \n",
    "    # Software & Programming\n",
    "    115903868,   # Software engineering\n",
    "    199360897,   # Programming language\n",
    "    111919701,   # Operating system\n",
    "    11413529,    # Algorithm\n",
    "    \n",
    "    # Systems & Architecture\n",
    "    118524514,   # Computer architecture\n",
    "    9390403,     # Computer hardware\n",
    "    120314980,   # Distributed computing\n",
    "    173608175,   # Parallel computing\n",
    "    79403827,    # Real-time computing\n",
    "    149635348,   # Embedded system\n",
    "    \n",
    "    # Networks & Security\n",
    "    31258907,    # Computer network\n",
    "    38652104,    # Computer security\n",
    "    108827166,   # Internet privacy\n",
    "    76155785,    # Telecommunications\n",
    "    136764020,   # World Wide Web\n",
    "    \n",
    "    # Graphics & Multimedia\n",
    "    121684516,   # Computer graphics (images)\n",
    "    49774154,    # Multimedia\n",
    "    44154836,    # Simulation\n",
    "    \n",
    "    # Human-Computer Interaction\n",
    "    107457646,   # Human-computer interaction\n",
    "    188147891,   # Cognitive science\n",
    "    \n",
    "    # Computational Methods (Interdisciplinary)\n",
    "    70721500,    # Computational biology\n",
    "    60644358,    # Bioinformatics\n",
    "    147597530,   # Computational chemistry\n",
    "    30475298,    # Computational physics\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(cs_related_field_ids)} CS-related field IDs\")\n",
    "\n",
    "# Identify columns\n",
    "field_name_column = None\n",
    "field_id_column = None\n",
    "\n",
    "for col in df_fields.columns:\n",
    "    col_lower = col.lower()\n",
    "    if 'name' in col_lower and field_name_column is None:\n",
    "        field_name_column = col\n",
    "    if 'id' in col_lower and 'field' in col_lower and field_id_column is None:\n",
    "        field_id_column = col\n",
    "\n",
    "print(f\"Using name column: '{field_name_column}'\")\n",
    "print(f\"Using ID column: '{field_id_column}'\")\n",
    "\n",
    "# Filter for CS-related fields\n",
    "cs_fields = df_fields[df_fields[field_id_column].isin(cs_related_field_ids)]\n",
    "\n",
    "if len(cs_fields) > 0:\n",
    "    print(f\"\\nFOUND: {len(cs_fields)} Computer Science related fields\\n\")\n",
    "    print(\"=\"*120)\n",
    "    print(cs_fields[[field_id_column, field_name_column]].to_string(index=False))\n",
    "    print(\"=\"*120)\n",
    "    \n",
    "    cs_field_ids = [int(x) for x in cs_fields[field_id_column].values]\n",
    "    print(f\"\\nTotal CS Field IDs: {len(cs_field_ids)}\")\n",
    "    \n",
    "    validation_passed = validation_passed and True\n",
    "else:\n",
    "    print(\"WARNING: No Computer Science fields found\")\n",
    "    validation_passed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "556af21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sampling Virginia Tech Papers ===\n",
      "\n",
      "PaperAuthorAffiliations columns: ['PaperID', 'AuthorID', 'AffiliationID', 'AuthorSequenceNumber']\n",
      "\n",
      "Reading sample (first 2M rows)...\n",
      "Sample size: 2,000,000 rows\n",
      "Using columns: paper='PaperID', author='AuthorID', affiliation='AffiliationID'\n",
      "\n",
      "FOUND: 733 VT paper-author records\n",
      "Unique papers: 413\n",
      "Unique authors: 608\n",
      "\n",
      "Sample Paper IDs: [62584, 224206, 365369, 380602, 648144]...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Sampling Virginia Tech Papers ===\\n\")\n",
    "\n",
    "if 'vt_affiliation_ids' not in locals() or len(vt_affiliation_ids) == 0:\n",
    "    print(\"Skipping - No Virginia Tech affiliations found\")\n",
    "else:\n",
    "    paa_file = os.path.join(DATA_DIR, 'SciSciNet_PaperAuthorAffiliations.tsv')\n",
    "    \n",
    "    sample_peek = pd.read_csv(paa_file, sep='\\t', nrows=1)\n",
    "    print(f\"PaperAuthorAffiliations columns: {list(sample_peek.columns)}\\n\")\n",
    "    \n",
    "    print(\"Reading sample (first 2M rows)...\")\n",
    "    df_paa_sample = pd.read_csv(paa_file, sep='\\t', nrows=2000000)\n",
    "    \n",
    "    print(f\"Sample size: {len(df_paa_sample):,} rows\")\n",
    "    \n",
    "    # Identify columns\n",
    "    paa_affil_col = None\n",
    "    paa_paper_col = None\n",
    "    paa_author_col = None\n",
    "    \n",
    "    for col in df_paa_sample.columns:\n",
    "        col_lower = col.lower()\n",
    "        if 'affiliation' in col_lower and 'id' in col_lower:\n",
    "            paa_affil_col = col\n",
    "        if 'paper' in col_lower and 'id' in col_lower:\n",
    "            paa_paper_col = col\n",
    "        if 'author' in col_lower and 'id' in col_lower:\n",
    "            paa_author_col = col\n",
    "    \n",
    "    print(f\"Using columns: paper='{paa_paper_col}', author='{paa_author_col}', affiliation='{paa_affil_col}'\")\n",
    "    \n",
    "    vt_papers_sample = df_paa_sample[df_paa_sample[paa_affil_col].isin(vt_affiliation_ids)]\n",
    "    \n",
    "    if len(vt_papers_sample) > 0:\n",
    "        print(f\"\\nFOUND: {len(vt_papers_sample):,} VT paper-author records\")\n",
    "        print(f\"Unique papers: {vt_papers_sample[paa_paper_col].nunique():,}\")\n",
    "        print(f\"Unique authors: {vt_papers_sample[paa_author_col].nunique():,}\")\n",
    "        \n",
    "        sample_paper_ids = vt_papers_sample[paa_paper_col].unique()[:10].tolist()\n",
    "        print(f\"\\nSample Paper IDs: {sample_paper_ids[:5]}...\")\n",
    "        \n",
    "        paper_id_col = paa_paper_col\n",
    "        author_id_col = paa_author_col\n",
    "        \n",
    "        validation_passed = validation_passed and True\n",
    "    else:\n",
    "        print(\"WARNING: No VT papers found in sample\")\n",
    "        validation_passed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "076448b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fetching Sample Paper Details ===\n",
      "\n",
      "Reading Papers.tsv sample (first 5M rows)...\n",
      "Sample size: 5,000,000 rows\n",
      "Columns: ['PaperID', 'DOI', 'DocType', 'Year', 'Date', 'JournalID', 'ConferenceSeriesID', 'Citation_Count', 'C10', 'Reference_Count', 'C5', 'Team_Size', 'Institution_Count', 'Disruption', 'Atyp_10pct_Z', 'Atyp_Pairs', 'Atyp_Median_Z', 'SB_B', 'SB_T', 'Patent_Count', 'Newsfeed_Count', 'Tweet_Count', 'NCT_Count', 'NIH_Count', 'NSF_Count', 'WSB_mu', 'WSB_sigma', 'WSB_Cinf']\n",
      "\n",
      "Found 1 sample VT papers\n",
      "\n",
      "========================================================================================================================\n",
      " PaperID   Year\n",
      "  365369 2002.0\n",
      "========================================================================================================================\n",
      "\n",
      "Year distribution (last 15 years):\n",
      "Year\n",
      "1973.0    2\n",
      "1975.0    2\n",
      "1979.0    1\n",
      "1991.0    2\n",
      "1993.0    4\n",
      "1995.0    3\n",
      "1997.0    1\n",
      "2002.0    1\n",
      "2003.0    1\n",
      "2004.0    1\n",
      "2006.0    5\n",
      "2007.0    5\n",
      "2008.0    1\n",
      "2010.0    1\n",
      "2013.0    3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Fetching Sample Paper Details ===\\n\")\n",
    "\n",
    "if 'sample_paper_ids' in locals() and len(sample_paper_ids) > 0:\n",
    "    papers_file = os.path.join(DATA_DIR, 'SciSciNet_Papers.tsv')\n",
    "    \n",
    "    print(\"Reading Papers.tsv sample (first 5M rows)...\")\n",
    "    df_papers_sample = pd.read_csv(papers_file, sep='\\t', nrows=5000000)\n",
    "    \n",
    "    print(f\"Sample size: {len(df_papers_sample):,} rows\")\n",
    "    print(f\"Columns: {list(df_papers_sample.columns)}\")\n",
    "    \n",
    "    sample_papers = df_papers_sample[df_papers_sample[paper_id_col].isin(sample_paper_ids)]\n",
    "    \n",
    "    if len(sample_papers) > 0:\n",
    "        print(f\"\\nFound {len(sample_papers)} sample VT papers\\n\")\n",
    "        print(\"=\"*120)\n",
    "        \n",
    "        title_col = None\n",
    "        for col in ['PaperTitle', 'OriginalTitle', 'Title']:\n",
    "            if col in sample_papers.columns:\n",
    "                title_col = col\n",
    "                break\n",
    "        \n",
    "        year_col = None\n",
    "        for col in ['Year', 'PublicationYear']:\n",
    "            if col in sample_papers.columns:\n",
    "                year_col = col\n",
    "                break\n",
    "        \n",
    "        cols_to_show = [paper_id_col]\n",
    "        if year_col:\n",
    "            cols_to_show.append(year_col)\n",
    "        if title_col:\n",
    "            cols_to_show.append(title_col)\n",
    "        \n",
    "        print(sample_papers[cols_to_show].to_string(index=False, max_colwidth=80))\n",
    "        print(\"=\"*120)\n",
    "        \n",
    "        if year_col:\n",
    "            vt_with_years = vt_papers_sample.merge(\n",
    "                df_papers_sample[[paper_id_col, year_col]], \n",
    "                on=paper_id_col, \n",
    "                how='left'\n",
    "            )\n",
    "            year_counts = vt_with_years[year_col].value_counts().sort_index()\n",
    "            print(f\"\\nYear distribution (last 15 years):\")\n",
    "            print(year_counts.tail(15))\n",
    "    else:\n",
    "        print(\"Sample papers not found in first 5M rows\")\n",
    "else:\n",
    "    print(\"Skipping - No sample paper IDs available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee07dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Checking for CS Papers at VT ===\n",
      "\n",
      "Reading PaperFields.tsv sample (first 5M rows)...\n",
      "Sample size: 5,000,000 rows\n",
      "Columns: ['PaperID', 'FieldID', 'Hit_1pct', 'Hit_5pct', 'Hit_10pct', 'C_f']\n",
      "Using columns: paper='PaperID', field='FieldID'\n",
      "\n",
      "Found 2 VT CS paper-field records\n",
      "Unique CS papers: 2\n",
      "\n",
      "CS fields found in sample:\n",
      " FieldID       Field_Name\n",
      "41008148 Computer science\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Checking for CS Papers at VT ===\\n\")\n",
    "\n",
    "if 'sample_paper_ids' in locals() and 'cs_field_ids' in locals():\n",
    "    paper_fields_file = os.path.join(DATA_DIR, 'SciSciNet_PaperFields.tsv')\n",
    "    \n",
    "    print(\"Reading PaperFields.tsv sample (first 5M rows)...\")\n",
    "    df_paper_fields_sample = pd.read_csv(paper_fields_file, sep='\\t', nrows=5000000)\n",
    "    \n",
    "    print(f\"Sample size: {len(df_paper_fields_sample):,} rows\")\n",
    "    print(f\"Columns: {list(df_paper_fields_sample.columns)}\")\n",
    "    \n",
    "    pf_paper_col = None\n",
    "    pf_field_col = None\n",
    "    \n",
    "    for col in df_paper_fields_sample.columns:\n",
    "        col_lower = col.lower()\n",
    "        if 'paper' in col_lower and 'id' in col_lower:\n",
    "            pf_paper_col = col\n",
    "        if 'field' in col_lower and 'id' in col_lower:\n",
    "            pf_field_col = col\n",
    "    \n",
    "    print(f\"Using columns: paper='{pf_paper_col}', field='{pf_field_col}'\")\n",
    "    \n",
    "    vt_cs_sample = df_paper_fields_sample[\n",
    "        (df_paper_fields_sample[pf_paper_col].isin(sample_paper_ids)) &\n",
    "        (df_paper_fields_sample[pf_field_col].isin(cs_field_ids))\n",
    "    ]\n",
    "    \n",
    "    if len(vt_cs_sample) > 0:\n",
    "        print(f\"\\nFound {len(vt_cs_sample)} VT CS paper-field records\")\n",
    "        print(f\"Unique CS papers: {vt_cs_sample[pf_paper_col].nunique()}\")\n",
    "        \n",
    "        # Show which CS fields are represented\n",
    "        cs_fields_in_sample = vt_cs_sample[pf_field_col].unique()\n",
    "        matching_fields = cs_fields[cs_fields[field_id_column].isin(cs_fields_in_sample)]\n",
    "        print(f\"\\nCS fields found in sample:\")\n",
    "        print(matching_fields[[field_id_column, field_name_column]].to_string(index=False))\n",
    "    else:\n",
    "        print(\"No VT CS papers found in this sample\")\n",
    "else:\n",
    "    print(\"Skipping - Missing prerequisites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b06685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Scope Estimation ===\n",
      "\n",
      "VT papers ratio in sample: 0.0367%\n",
      "Estimated total VT paper-author records: ~151,364\n",
      "Estimated unique VT papers: ~85,284\n",
      "Estimated VT CS papers: ~412\n",
      "\n",
      "Papers from 2015-present in sample: 0\n",
      "Papers from 2020-present in sample: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Data Scope Estimation ===\\n\")\n",
    "\n",
    "if 'vt_papers_sample' in locals() and len(vt_papers_sample) > 0:\n",
    "    sample_size = 2000000\n",
    "    vt_count_in_sample = len(vt_papers_sample)\n",
    "    estimated_ratio = vt_count_in_sample / sample_size\n",
    "    \n",
    "    estimated_total_vt_records = int(estimated_ratio * 413_000_000)\n",
    "    estimated_vt_papers = int(vt_papers_sample[paper_id_col].nunique() * (413_000_000 / sample_size))\n",
    "    \n",
    "    print(f\"VT papers ratio in sample: {estimated_ratio*100:.4f}%\")\n",
    "    print(f\"Estimated total VT paper-author records: ~{estimated_total_vt_records:,}\")\n",
    "    print(f\"Estimated unique VT papers: ~{estimated_vt_papers:,}\")\n",
    "    \n",
    "    if 'vt_cs_sample' in locals() and len(vt_cs_sample) > 0:\n",
    "        cs_ratio = vt_cs_sample[pf_paper_col].nunique() / vt_papers_sample[paper_id_col].nunique()\n",
    "        estimated_cs_papers = int(estimated_vt_papers * cs_ratio)\n",
    "        print(f\"Estimated VT CS papers: ~{estimated_cs_papers:,}\")\n",
    "    \n",
    "    if 'year_counts' in locals():\n",
    "        recent_years = year_counts[year_counts.index >= 2015]\n",
    "        print(f\"\\nPapers from 2015-present in sample: {recent_years.sum()}\")\n",
    "        print(f\"Papers from 2020-present in sample: {year_counts[year_counts.index >= 2020].sum()}\")\n",
    "else:\n",
    "    print(\"Cannot estimate - no sample data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb235224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "VALIDATION SUMMARY\n",
      "========================================================================================================================\n",
      "All validation checks PASSED\n",
      "Virginia Tech: Main campus only (ID: 859038795)\n",
      "Computer Science fields: 39 fields\n",
      "Sample VT papers found: 733 records\n",
      "Sample VT CS papers found: 2 unique papers\n",
      "Dataset is valid and ready for processing\n",
      "\n",
      "Configuration saved to: validation_config.py\n",
      "Total CS-related fields included: 39\n",
      "\n",
      "Ready to proceed with 02_preprocessing.ipynb\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "if validation_passed:\n",
    "    print(\"All validation checks PASSED\")\n",
    "    print(f\"Virginia Tech: Main campus only (ID: {vt_affiliation_ids[0]})\")\n",
    "    print(f\"Computer Science fields: {len(cs_fields)} fields\")\n",
    "    if 'vt_papers_sample' in locals():\n",
    "        print(f\"Sample VT papers found: {len(vt_papers_sample):,} records\")\n",
    "    if 'vt_cs_sample' in locals() and len(vt_cs_sample) > 0:\n",
    "        print(f\"Sample VT CS papers found: {vt_cs_sample[pf_paper_col].nunique()} unique papers\")\n",
    "    print(\"Dataset is valid and ready for processing\")\n",
    "    \n",
    "    config_content = f\"\"\"# Auto-generated from 01_validation.ipynb\n",
    "\n",
    "# Virginia Tech Configuration (Main Campus Only)\n",
    "VT_AFFILIATION_IDS = {vt_affiliation_ids}\n",
    "AFFILIATION_ID_COL = '{affiliation_id_col}'\n",
    "AFFILIATION_NAME_COL = '{affiliation_name_col}'\n",
    "\n",
    "# Computer Science Configuration (All CS-Related Fields)\n",
    "CS_FIELD_IDS = {cs_field_ids}\n",
    "FIELD_ID_COL = '{field_id_column}'\n",
    "FIELD_NAME_COL = '{field_name_column}'\n",
    "\n",
    "# Column mappings\n",
    "PAPER_ID_COL = '{paper_id_col if 'paper_id_col' in locals() else 'PaperID'}'\n",
    "AUTHOR_ID_COL = '{author_id_col if 'author_id_col' in locals() else 'AuthorID'}'\n",
    "PAA_AFFIL_COL = '{paa_affil_col if 'paa_affil_col' in locals() else 'AffiliationID'}'\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = '{DATA_DIR}'\n",
    "\n",
    "# Display names\n",
    "VT_AFFILIATION_NAMES = {list(all_vt_results[affiliation_name_col].values)}\n",
    "CS_FIELD_NAMES = {list(cs_fields[field_name_column].values)}\n",
    "\"\"\"\n",
    "    \n",
    "    config_file = 'validation_config.py'\n",
    "    with open(config_file, 'w') as f:\n",
    "        f.write(config_content)\n",
    "    \n",
    "    print(f\"\\nConfiguration saved to: {config_file}\")\n",
    "    print(f\"Total CS-related fields included: {len(cs_field_ids)}\")\n",
    "    print(\"\\nReady to proceed with 02_preprocessing.ipynb\")\n",
    "    \n",
    "else:\n",
    "    print(\"Validation FAILED\")\n",
    "    print(\"Please review errors above\")\n",
    "\n",
    "print(\"=\"*120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
